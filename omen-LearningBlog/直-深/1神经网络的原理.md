# 神经网络的原理

![image-20240106101616915](https://evinci.oss-cn-hangzhou.aliyuncs.com/img/image-20240106101616915.png)

## 感知机模型

神经网络其实是输入层、隐藏层和输出层之间的关系表示

其本质上是线性关系的组合表示，而冠以神经元和神经网络的名字只是试图像让该种模型具有与神经元和神经网络类似的逐层向前推进的能力，真正的神经元和神经网络的结构比该种线性关系的表示模型要复杂百倍

当隐藏层为一层时，我们也称该模型为感知机模型；当隐藏层不止一层时，我们也称该种模型为多层感知机模型

## 隐藏层带来的退化问题

![image-20240106100448324](https://evinci.oss-cn-hangzhou.aliyuncs.com/img/image-20240106100448324.png)

因为输入层到隐藏层之间的关系可以用一个线性方程组来进行表示，隐藏层到输出层之间的关系也可以用一个线性方程组来表示

而根据线性代数的内容我们可知，**一系列线性方程的运算最终都可以用一个线性方程来表示**，即上述两个线性方程联立是可以用一个线性方程来表达的，对于两层的神经网络是这样，对于100层的神经网络依然也是这样，所以这就使得多层的隐藏层无法有效的发挥作用，从而出现了**模型退化**的问题

因此此时要引入激活函数（activation）来进行**非线性变换**，其中激活函数要求**必须是可导**的

常见的激活函数有阶跃函数、sigmoid函数和relu函数，其中**relu函数最为常用**，因为阶跃函数**只有二值**，可取值太少；sigmoid函数**当x的绝对值比较大时，曲线的斜率变化很小**，会产生**梯度消失问题**

![image-20240106101217946](https://evinci.oss-cn-hangzhou.aliyuncs.com/img/image-20240106101217946.png)