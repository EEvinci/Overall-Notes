# Prompt优化技巧

## Trick-戴高帽

### 戴高帽的效果好的原理

**网上搜集的数据**在送入模型中是其实是**带有标签的**，那么在“戴高帽”的过程中，可能是将“高帽”中的标签进行了筛选和对应，从而输出了那些带“大师”和“专家”的数据，这样的数据可能相对来说质量会更高一些

戴高帽看起来是增加了一些与数据来源无关的词汇，但实际上是比较接近的

本质上是调用了一些比较有特色的标签，或者效果比较好的权重

态度越友好，产生的效果往往会越好

但是戴高帽只是一个Trick，即戏法，并不适用于所有的场景，只会在一些场景中产生比较好的效果

![image-20230523172959693](C:\Users\PC\AppData\Roaming\Typora\typora-user-images\image-20230523172959693.png)

![image-20230523172811445](C:\Users\PC\AppData\Roaming\Typora\typora-user-images\image-20230523172811445.png)

## Trick-思维链

这和训练过程中的数据喂入的方式有关：之前训练的时候可能是一段文本，但是现在是**一个问题和该问题的详细的解决思路**，是有逻辑和条理的，所以模型会学习这样的数据内在逻辑和模式

从而学会思维链的表达方式

![image-20230523173314449](C:\Users\PC\AppData\Roaming\Typora\typora-user-images\image-20230523173314449.png)

## Trick

### Zero-shot

不给任何提示就让模型给出答案



### Few-shot

给出一小部分的提示，让模型输出内容

![image-20230523173548876](C:\Users\PC\AppData\Roaming\Typora\typora-user-images\image-20230523173548876.png)

### 做假设

为了减少大模型输出错误和虚假回答的方法

布鲁弗莱（bluefly-蓝翔）

对模型的回答做出错误的假设，并让其进行规避和错误的说明，而不是一味的让其完成需求，这会使得模型没有真实数据而编造数据来满足回答的需求

`如果你的数据存在问题,例如数据不准确, 缺乏时效性等, 那么可以给出否定的答复, 例如: 目前没有相关的数据可供参考`

![image-20230523173753838](C:\Users\PC\AppData\Roaming\Typora\typora-user-images\image-20230523173753838.png)